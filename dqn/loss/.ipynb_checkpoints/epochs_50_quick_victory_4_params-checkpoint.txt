
import torch.optim as optim

##from DQN_model import DQN
from DQN_learn import OptimizerSpec
from utils.schedule import LinearSchedule


import torch
import numpy as np
import random

%run ../game
%run ../preprocessor
%run DQN_model
%run DQN_learn

SEED = 1
BATCH_SIZE = 32
GAMMA = 0.99
REPLAY_BUFFER_SIZE = 10000
LEARNING_STARTS = 128
#LEARNING_STARTS = 5 #debug for back_prop
LEARNING_FREQ = 4
FRAME_HISTORY_LEN = 4
TARGER_UPDATE_FREQ = 100
LEARNING_RATE = 0.00025
ALPHA = 0.95
EPS = 0.01
num_episodes = 50


optimizer_spec = OptimizerSpec(
        constructor=optim.RMSprop,
        kwargs=dict(lr=LEARNING_RATE, alpha=ALPHA, eps=EPS),
    )

exploration_schedule = LinearSchedule(1000000, 0.1)
    
n_frames = 1
n_channels = 3
original_width = 256
original_height = 240
scaled_width = 84
scaled_height = 84

game_visible = True
mario_scale = 2.0
mario_state = 0
mario_timer = 200
mario_fps = 30
level_path = "/levels/custom/quick_victory_4.txt"
preprocess = Preprocessor(n_frames, n_channels, original_height, original_width, scaled_height, scaled_width)
game = Game(game_visible, mario_scale, mario_state, mario_timer, mario_fps, level_path, preprocess)

agent = DDQNAgent(game, num_episodes, DQN, optimizer_spec, exploration_schedule, REPLAY_BUFFER_SIZE, BATCH_SIZE, GAMMA, LEARNING_STARTS, LEARNING_FREQ, FRAME_HISTORY_LEN, TARGER_UPDATE_FREQ)
agent.train()

