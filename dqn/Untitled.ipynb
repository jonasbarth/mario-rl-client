{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch.optim as optim\n",
    "\n",
    "from DQN_model import DQN\n",
    "from DQN_learn import OptimizerSpec, dqn_learing\n",
    "from utils.schedule import LinearSchedule\n",
    "\n",
    "import ppaquette_gym_super_mario\n",
    "\n",
    "from gym import wrappers\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from utils.atari_wrapper import wrap_deepmind\n",
    "SEED = 1\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "REPLAY_BUFFER_SIZE = 1000000\n",
    "LEARNING_STARTS = 10000\n",
    "#LEARNING_STARTS = 32 #debug for back_prop\n",
    "LEARNING_FREQ = 4\n",
    "FRAME_HISTORY_LEN = 4\n",
    "TARGER_UPDATE_FREQ = 3000\n",
    "LEARNING_RATE = 0.00025\n",
    "ALPHA = 0.95\n",
    "EPS = 0.01\n",
    "\n",
    "def main(env):\n",
    "\n",
    "    optimizer_spec = OptimizerSpec(\n",
    "        constructor=optim.RMSprop,\n",
    "        kwargs=dict(lr=LEARNING_RATE, alpha=ALPHA, eps=EPS),\n",
    "    )\n",
    "\n",
    "    exploration_schedule = LinearSchedule(1000000, 0.1)\n",
    "\n",
    "    dqn_learing(\n",
    "        env=env,\n",
    "        q_func=DQN,\n",
    "        optimizer_spec=optimizer_spec,\n",
    "        exploration=exploration_schedule,\n",
    "        replay_buffer_size=REPLAY_BUFFER_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        gamma=GAMMA,\n",
    "        learning_starts=LEARNING_STARTS,\n",
    "        learning_freq=LEARNING_FREQ,\n",
    "        frame_history_len=FRAME_HISTORY_LEN,\n",
    "        target_update_freq=TARGER_UPDATE_FREQ,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
